Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:19,  6.49s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.21s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.91s/it]
`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.24it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.26it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]
`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.87s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.89s/it]
`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
=>> PBS: job killed: walltime 604835 exceeded limit 604800
